{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bahador1/BahadorColabNotes/blob/main/profit_alloc_shaply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23df3bca",
      "metadata": {
        "id": "23df3bca"
      },
      "source": [
        "# weighted FedAvg using shap\n",
        "\n",
        "- test the effectiveness of *profit allocation using Shapley Value* in Horizontal Federated Learning systems.\n",
        "\n",
        "- The system has the following customizable functions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "LhOjwFjgtIJF"
      },
      "id": "LhOjwFjgtIJF"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b9ef543f",
      "metadata": {
        "id": "b9ef543f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a461dc8d-46fd-4acb-ceb0-1a2973b0330e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79dd402d94f0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Load libraries\n",
        "import math, random, copy, os, glob, time\n",
        "from itertools import chain, combinations, permutations\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision as tv\n",
        "from torchvision import datasets, transforms as T\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Standardize randomness\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initializations and definitions(ds, model )"
      ],
      "metadata": {
        "id": "7oCXQGSh5nIz"
      },
      "id": "7oCXQGSh5nIz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define system hyper-parameters [ EDIT HERE ]"
      ],
      "metadata": {
        "id": "EMhYlYkZtMHc"
      },
      "id": "EMhYlYkZtMHc"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e4f9a275",
      "metadata": {
        "id": "e4f9a275"
      },
      "outputs": [],
      "source": [
        "## USER DEFINED EXPERIMENT PARAMETERS\n",
        "\n",
        "# Federated network settings\n",
        "MODEL_SIZE = 'MEDIUM'            # SMALL / MEDIUM / LARGE\n",
        "REWARD_METRICS = ['LOSS']        # LOSS / ACCURACY / F1 - Metrics sum to select best model for each communication round\n",
        "COMM_ROUNDS = 10                 # Number of communication rounds between server and clients\n",
        "SHAPLEY_FILTER = False           # True / False - If true, select only the best coalition model per communication round\n",
        "COALITION_LIMIT = 0              # Limits the size of individual coalitions (Set as non-positive number to disable limit)\n",
        "\n",
        "# Training dataset settings\n",
        "DATASET_TYPE = 'MNIST'      # MNIST / EMNIST\n",
        "DISTRIBUTION_TYPE = 'IID'   # IID / NIID_1 / NIID_2 / NIID_12/ TODO: noisey\n",
        "BATCH_SIZE = 64             # Dataset batch size\n",
        "\n",
        "# Training hyper-parameters and functions for the Federated modeel\n",
        "INIT_LEARN_RATE = 0.1\n",
        "LOSS_FUNC = nn.CrossEntropyLoss\n",
        "OPTIMIZER = torch.optim.SGD\n",
        "MOMENTUM = .9\n",
        "WEIGHT_DECAY = 1e-5\n",
        "EPOCHS = 10                  # Number of epochs each client will train over.\n",
        "\n",
        "# Client behaviours each parameter represents the number of clients running in the network\n",
        "NUM_NORMAL_CLIENTS = 4          # Client trains model and returns updated parameters\n",
        "NUM_FREERIDER_CLIENTS = 0       # Client does not train model and returns original parameters\n",
        "NUM_ADVERSARIAL_CLIENTS = 1     # Client returns randomized parameters TODO: to see if shapley works"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize system and define helper functions\n",
        "- `createDirectory`, `deleteAllModels`, `aggListOfDict`, `powerset`"
      ],
      "metadata": {
        "id": "elz2GPwms4wW"
      },
      "id": "elz2GPwms4wW"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "06448f18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06448f18",
        "outputId": "215e65a8-8775-4d0c-b02c-2f57efe25c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "\"./models/ShapleyValue/server/server_model.pt\" deleted.\n",
            "\"./models/ShapleyValue/client/client_0.pt\" deleted.\n",
            "\"./models/ShapleyValue/client/client_4.pt\" deleted.\n",
            "\"./models/ShapleyValue/client/client_3.pt\" deleted.\n",
            "\"./models/ShapleyValue/client/client_2.pt\" deleted.\n",
            "\"./models/ShapleyValue/client/client_1.pt\" deleted.\n",
            "\n",
            "Libraries and directories initialized.\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Create subdirectories\n",
        "model_path = './models'\n",
        "\n",
        "def createDirectory(path):\n",
        "    pathExists = os.path.exists(path)\n",
        "    if not pathExists:\n",
        "        print(f'\"{path}\" does not exist.')\n",
        "        os.makedirs(path)\n",
        "        print(f'\"{path}\" created.')\n",
        "\n",
        "# createDirectory(model_path)\n",
        "\n",
        "# Delete existing .pt files from previous run\n",
        "def deleteAllModels(path):\n",
        "    filepaths = glob.glob(f'{path}/**/*.pt', recursive=True)\n",
        "    for filepath in filepaths:\n",
        "        os.remove(filepath)\n",
        "        print(f'\"{filepath}\" deleted.')\n",
        "\n",
        "deleteAllModels(model_path)\n",
        "\n",
        "# Complete\n",
        "print('\\nLibraries and directories initialized.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "# Recipe modified from Python itertools documentation:\n",
        "# https://docs.python.org/3/library/itertools.html#itertools-recipes\n",
        "def powerset(iterable, no_null = True):\n",
        "    \"powerset([1,2,3]) --> (if !no_null) (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(1 if no_null else 0, len(s)+1))\n",
        "\n",
        "def aggListOfDicts(lst):\n",
        "    '''\n",
        "        Combines a list of dictionaries into a dictionary of lists\n",
        "    '''\n",
        "    agg = {}\n",
        "    for dct in lst:\n",
        "        for name, val in dct.items():\n",
        "            if name in agg:\n",
        "                agg[name] += [val]\n",
        "            else:\n",
        "                agg[name] = [val]\n",
        "\n",
        "    return agg"
      ],
      "metadata": {
        "id": "ZB5jX0a4BEWV"
      },
      "id": "ZB5jX0a4BEWV",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e1d7f0e",
      "metadata": {
        "id": "9e1d7f0e"
      },
      "source": [
        "### Setup train and test datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "501bcfb6",
      "metadata": {
        "id": "501bcfb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899374bd-a255-4962-ac40-13fd2cd2852d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST training dataset has 60000 samples.\n",
            "MNIST test dataset has 10000 samples.\n"
          ]
        }
      ],
      "source": [
        "# Download training and test data from open datasets\n",
        "\n",
        "# MLP model uses Fashion-MNIST\n",
        "if DATASET_TYPE == 'MNIST':\n",
        "  train_data = datasets.MNIST(\n",
        "      root=\"data\",\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=T.ToTensor(),\n",
        "  )\n",
        "\n",
        "  test_data = datasets.MNIST(\n",
        "      root=\"data\",\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=T.ToTensor(),\n",
        "  )\n",
        "\n",
        "  CLASS_SIZE = 10\n",
        "\n",
        "print(f'{DATASET_TYPE} training dataset has {len(train_data)} samples.')\n",
        "print(f'{DATASET_TYPE} test dataset has {len(test_data)} samples.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data[0][0]), type(train_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USSc6VA_txeQ",
        "outputId": "e91110a3-69d9-4b3e-dc63-33f6800bc2dc"
      },
      "id": "USSc6VA_txeQ",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, int)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1705b7c1",
      "metadata": {
        "id": "1705b7c1"
      },
      "outputs": [],
      "source": [
        "# Functions to split dataset based on IID or Non-IID selection\n",
        "\n",
        "def prepareIID(dataset, num_clients):\n",
        "    '''\n",
        "        Prepares IID training datasets for each client\n",
        "    '''\n",
        "    dataset_split = [[] for i in range(num_clients)]\n",
        "\n",
        "    for idx, sample in enumerate(dataset):\n",
        "        dataset_split[idx%num_clients] += [sample]\n",
        "\n",
        "    return dataset_split\n",
        "\n",
        "def prepareNIID1(dataset, num_clients):\n",
        "    '''\n",
        "        Prepares NIID-1 training datasets for each client (Overlapping sample sets)\n",
        "    '''\n",
        "    dataset_split = [[] for i in range(num_clients)]\n",
        "\n",
        "    for idx, sample in enumerate(dataset):\n",
        "        dataset_split[idx%num_clients] += [random.choice(dataset)]\n",
        "\n",
        "    return dataset_split\n",
        "\n",
        "def prepareNIID2(dataset, num_clients):\n",
        "    '''\n",
        "        Prepares NIID-1 training datasets for each client (Unequal data distribution)\n",
        "    '''\n",
        "    dataset_split = [[] for i in range(num_clients)]\n",
        "\n",
        "    for idx, sample in enumerate(dataset):\n",
        "        dataset_split[random.randint(0,num_clients-1)] += [sample]\n",
        "\n",
        "    return dataset_split\n",
        "\n",
        "def prepareNIID12(dataset, num_clients):\n",
        "    '''\n",
        "        Prepares NIID-1+2 training datasets for each client\n",
        "        (Overlapping sample sets + Unequal data distribution)\n",
        "    '''\n",
        "    dataset_split = [[] for i in range(num_clients)]\n",
        "\n",
        "    for sample in dataset:\n",
        "        dataset_split[random.randint(0,num_clients-1)] += [random.choice(dataset)]\n",
        "\n",
        "    return dataset_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "46c09179-8d6a-405a-8531-b8fdef6d2aea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46c09179-8d6a-405a-8531-b8fdef6d2aea",
        "outputId": "66d110da-b6be-4e59-ca36-20c424c8a3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Split training dataset for clients\n",
        "NUM_OF_CLIENTS = NUM_NORMAL_CLIENTS + NUM_FREERIDER_CLIENTS + NUM_ADVERSARIAL_CLIENTS\n",
        "if DISTRIBUTION_TYPE == 'IID':\n",
        "    train_datasets = prepareIID(train_data, NUM_OF_CLIENTS)\n",
        "elif DISTRIBUTION_TYPE == 'NIID_1':\n",
        "    train_datasets = prepareNIID1(train_data, NUM_OF_CLIENTS)\n",
        "elif DISTRIBUTION_TYPE == 'NIID_2':\n",
        "    train_datasets = prepareNIID2(train_data, NUM_OF_CLIENTS)\n",
        "elif DISTRIBUTION_TYPE == 'NIID_12':\n",
        "    train_datasets = prepareNIID12(train_data, NUM_OF_CLIENTS)\n",
        "\n",
        "train_dataloaders = [DataLoader(train_dataset, batch_size=BATCH_SIZE) for train_dataset in train_datasets]\n",
        "\n",
        "# Sanity check a training dataloader\n",
        "for X, y in train_dataloaders[0]:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test dataloader.\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE*2)\n",
        "\n",
        "# Sanity check test dataloader\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBhE7HtAffR0",
        "outputId": "b0bdbde8-e871-4c1a-af26-cd52b4c64858"
      },
      "id": "yBhE7HtAffR0",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([128, 1, 28, 28])\n",
            "Shape of y: torch.Size([128]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c3c954",
      "metadata": {
        "id": "83c3c954"
      },
      "source": [
        "### Define neural nework models/and checkpoints functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "370f127a",
      "metadata": {
        "id": "370f127a"
      },
      "outputs": [],
      "source": [
        "# Define models\n",
        "\n",
        "class SmallMLP(nn.Module):\n",
        "    '''\n",
        "        Multi-Layer Perceptron\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(SmallMLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, CLASS_SIZE)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "class MediumMLP(nn.Module):\n",
        "    '''\n",
        "        Multi-Layer Perceptron\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(MediumMLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, CLASS_SIZE)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "class LargeMLP(nn.Module):\n",
        "    '''\n",
        "        Multi-Layer Perceptron\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(LargeMLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, CLASS_SIZE)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a75f620a",
      "metadata": {
        "id": "a75f620a"
      },
      "outputs": [],
      "source": [
        "# Define checkpoint functions (Simulates data exchange between clients and server)\n",
        "\n",
        "def saveCheckpoint(name, model_state_dict, optimizer_state_dict, filepath, verbose=False):\n",
        "    '''\n",
        "        Saves state dictionaries of model and optimizer as a .pt file\n",
        "    '''\n",
        "    torch.save({\n",
        "        'name': name,\n",
        "        'model_state_dict': model_state_dict,\n",
        "        'optimizer_state_dict': optimizer_state_dict,\n",
        "    }, filepath)\n",
        "\n",
        "    if verbose:\n",
        "        print(f'\\n\"{name}\" model saved as \"{filepath}\".\\n')\n",
        "\n",
        "    return True\n",
        "\n",
        "def loadCheckpoint(filepath, verbose=False):\n",
        "    '''\n",
        "        Loads and returns the state dictionaries of model and optimizer from a .pt file\n",
        "    '''\n",
        "    checkpoint = torch.load(filepath)\n",
        "    if verbose:\n",
        "        name = checkpoint['name']\n",
        "        print(f'\\n\"{name}\" model loaded from \"{filepath}\".\\n')\n",
        "    return checkpoint\n",
        "\n",
        "def print_parameters(model):\n",
        "    '''\n",
        "        Outputs the learnable parameter counts for each layer and in total\n",
        "    '''\n",
        "    print('Model Layer Parameters:\\n')\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "            if not parameter.requires_grad:\n",
        "                continue\n",
        "            params = parameter.numel()\n",
        "            print(f'{name} - {params} parameters')\n",
        "            total_params += params\n",
        "    print(f'\\n>>Total - {total_params} parameters\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Federated Model and hyper-parameters"
      ],
      "metadata": {
        "id": "WQnmC_Lvtngj"
      },
      "id": "WQnmC_Lvtngj"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2e873561-7eb6-4c34-8f88-40bae860bc8a",
      "metadata": {
        "id": "2e873561-7eb6-4c34-8f88-40bae860bc8a"
      },
      "outputs": [],
      "source": [
        "# Define network model architecture\n",
        "FederatedModel = None\n",
        "\n",
        "if MODEL_SIZE == 'SMALL':\n",
        "    FederatedModel = SmallMLP\n",
        "elif MODEL_SIZE == 'MEDIUM':\n",
        "    FederatedModel = MediumMLP\n",
        "elif MODEL_SIZE == 'LARGE':\n",
        "    FederatedModel = LargeMLP\n",
        "\n",
        "# print_parameters(FederatedModel())\n",
        "\n",
        "# Define network training functions and hyper-parameters\n",
        "FederatedLossFunc = LOSS_FUNC\n",
        "FederatedOptimizer = OPTIMIZER\n",
        "FederatedLearnRate = INIT_LEARN_RATE\n",
        "FederatedMomentum = MOMENTUM\n",
        "FederatedWeightDecay = WEIGHT_DECAY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a0ce58",
      "metadata": {
        "id": "d0a0ce58"
      },
      "source": [
        "## Server functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5e69fdd6",
      "metadata": {
        "id": "5e69fdd6"
      },
      "outputs": [],
      "source": [
        "def initServer(model_path,folder_name,dataloader):\n",
        "    '''\n",
        "        Initializes server model and returns object with attributes\n",
        "    '''\n",
        "    print('Initializing server model...')\n",
        "    # Spawn server model and functions\n",
        "    server_name = 'server'\n",
        "    server_model = FederatedModel().to(device)\n",
        "    server_loss_func = FederatedLossFunc()\n",
        "    server_optimizer = FederatedOptimizer(server_model.parameters(), lr=FederatedLearnRate, momentum=FederatedMomentum, weight_decay=FederatedWeightDecay)\n",
        "    server_dataloader = dataloader\n",
        "\n",
        "    print(server_model,'\\n')\n",
        "    print(server_optimizer)\n",
        "\n",
        "    createDirectory(f'{model_path}/{folder_name}/server')\n",
        "    createDirectory(f'{model_path}/{folder_name}/client')\n",
        "\n",
        "    # Collect objects into a reference dictionary\n",
        "    server = {\n",
        "        'name': server_name,\n",
        "        'model': server_model,\n",
        "        'dataloader': server_dataloader,\n",
        "        'optimizer': server_optimizer,\n",
        "        'loss_func': server_loss_func,\n",
        "        'filepath': f'{model_path}/{folder_name}/server/server_model.pt',\n",
        "        'client_filepath': f'{model_path}/{folder_name}/client'\n",
        "    }\n",
        "\n",
        "    # Save server model state_dicts (simulating public access to server model parameters)\n",
        "    saveCheckpoint(\n",
        "        server_name,\n",
        "        server_model.state_dict(),\n",
        "        server_optimizer.state_dict(),\n",
        "        server['filepath'],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return server"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03c568b",
      "metadata": {
        "id": "a03c568b"
      },
      "source": [
        "## Clients functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "84116d06",
      "metadata": {
        "id": "84116d06"
      },
      "outputs": [],
      "source": [
        "def initClients(num_norm,num_free,num_avsl,server,dataloaders):\n",
        "  '''\n",
        "      Initializes clients objects and returns a list of client object\n",
        "  '''\n",
        "\n",
        "  print('Initializing clients...')\n",
        "  # Setup client devices\n",
        "  behaviour_list = [\n",
        "      *['NORMAL' for i in range(num_norm)],\n",
        "      *['FREERIDER' for i in range(num_free)],\n",
        "      *['ADVERSARIAL' for i in range(num_avsl)],\n",
        "  ]\n",
        "\n",
        "  clients = []\n",
        "  for n, behaviour in enumerate(behaviour_list):\n",
        "      # Spawn client model and functions\n",
        "      client_name = f'client_{n}'\n",
        "\n",
        "      # Collect client's objects into a reference dictionary\n",
        "      clients += [{\n",
        "          'name': client_name,\n",
        "          'behaviour': behaviour,\n",
        "          'filepath': f'{server[\"client_filepath\"]}/{client_name}.pt',\n",
        "          'dataloader': dataloaders[n]\n",
        "      }]\n",
        "\n",
        "  print('Client Name / Behaviour:', [(client['name'], client['behaviour']) for client in clients], '\\n')\n",
        "\n",
        "  return clients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d386ef",
      "metadata": {
        "id": "83d386ef"
      },
      "source": [
        "\n",
        "\n",
        "## Define train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4cec27bf",
      "metadata": {
        "id": "4cec27bf"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, verbose=False):\n",
        "    '''\n",
        "        Trains a NN model over a dataloader\n",
        "    '''\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ae205d40",
      "metadata": {
        "id": "ae205d40"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn, verbose=False):\n",
        "    '''\n",
        "        Tests a NN model over a dataloader\n",
        "    '''\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, correct, f1 = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred = model(X)\n",
        "            test_loss += loss_fn(y_pred, y).item()\n",
        "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            f1 += f1_score(y.cpu(), y_pred.argmax(1).cpu(), average='micro')\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    f1 /= num_batches\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Test Error: \\n Accuracy: {correct:>8f}, Avg loss: {test_loss:>8f}, F1: {f1:>8f} \\n\")\n",
        "\n",
        "    return test_loss, correct, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9f13f57",
      "metadata": {
        "id": "b9f13f57"
      },
      "source": [
        "## Client training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3d26b2c8",
      "metadata": {
        "id": "3d26b2c8"
      },
      "outputs": [],
      "source": [
        "def trainClients(clients, server):\n",
        "    '''\n",
        "        Trains a list of client devices and saves their parameters\n",
        "    '''\n",
        "    loss, acc, f1 = {}, {}, {}\n",
        "    for client in clients:\n",
        "        train_loss, test_loss, test_acc, test_f1 = trainClient(client, server)\n",
        "\n",
        "        # Aggregate statistics\n",
        "        loss[client['name']] = test_loss\n",
        "        acc[client['name']] = test_acc\n",
        "        f1[client['name']] = test_f1\n",
        "\n",
        "    return loss, acc, f1\n",
        "\n",
        "def trainClient(client, server):\n",
        "    '''\n",
        "        Train a client device and save its parameters\n",
        "    '''\n",
        "    # Read client behaviour setting\n",
        "    client_behaviour = client['behaviour']\n",
        "\n",
        "    # Load local dataset\n",
        "    client_dataloader = client['dataloader']\n",
        "\n",
        "    # Get client model and functions\n",
        "    client_name = client['name']\n",
        "    client_model = FederatedModel().to(device)\n",
        "    client_loss_fn = FederatedLossFunc()\n",
        "    client_optimizer = FederatedOptimizer(client_model.parameters(), lr=FederatedLearnRate, momentum=FederatedMomentum, weight_decay=FederatedWeightDecay)\n",
        "\n",
        "    # If client is adversarial, they return randomized parameters\n",
        "    if client_behaviour == 'ADVERSARIAL':\n",
        "        # Save client model state_dicts (simulating client uploading model parameters to server)\n",
        "        saveCheckpoint(\n",
        "            client_name,\n",
        "            client_model.state_dict(),\n",
        "            client_optimizer.state_dict(),\n",
        "            client['filepath'],\n",
        "        )\n",
        "\n",
        "        test_loss, test_acc, test_f1 = test(server['dataloader'], client_model, client_loss_fn)\n",
        "        print(f\"{client_name} ({client_behaviour}) Test Acc: {test_acc:>8f}, Loss: {test_loss:>8f}, F1: {test_f1:>8f}\")\n",
        "\n",
        "        return 0, test_loss, test_acc, test_f1\n",
        "\n",
        "    # Load server model state_dicts (simulating client downloading server model parameters)\n",
        "    checkpoint = loadCheckpoint(server['filepath'])\n",
        "\n",
        "    client_model.load_state_dict(checkpoint['model_state_dict']) # Using current server model parameters\n",
        "\n",
        "    # If client is a freeloader, they return the same server model parameters\n",
        "    if client_behaviour == 'FREERIDER':\n",
        "        # Save client model state_dicts (simulating client uploading model parameters to server)\n",
        "        saveCheckpoint(\n",
        "            client_name,\n",
        "            client_model.state_dict(),\n",
        "            client_optimizer.state_dict(),\n",
        "            client['filepath'],\n",
        "        )\n",
        "\n",
        "        test_loss, test_acc, test_f1 = test(server['dataloader'], client_model, client_loss_fn)\n",
        "        print(f\"{client_name} ({client_behaviour}) Test Acc: {test_acc:>8f}, Loss: {test_loss:>8f}, F1: {test_f1:>8f}\")\n",
        "\n",
        "        return 0, test_loss, test_acc, test_f1\n",
        "\n",
        "    # If client is normal, they train client over N epochs\n",
        "    epochs = EPOCHS\n",
        "    print(f'Training {client_name} over {epochs} epochs...')\n",
        "    for t in range(epochs):\n",
        "        train_loss = train(client_dataloader, client_model, client_loss_fn, client_optimizer)\n",
        "\n",
        "    test_loss, test_acc, test_f1 = test(server['dataloader'], client_model, client_loss_fn)\n",
        "    print(f\"{client_name} ({client_behaviour}) Test Acc: {test_acc:>8f}, Loss: {test_loss:>8f}, F1: {test_f1:>8f}\")\n",
        "\n",
        "    # Save client model state_dicts (simulating client uploading model parameters to server)\n",
        "    saveCheckpoint(\n",
        "        client_name,\n",
        "        client_model.state_dict(),\n",
        "        client_optimizer.state_dict(),\n",
        "        client['filepath'],\n",
        "    )\n",
        "\n",
        "    return train_loss, test_loss, test_acc, test_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b0206a",
      "metadata": {
        "id": "f0b0206a"
      },
      "source": [
        "## FedAvg core function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "05108b07",
      "metadata": {
        "id": "05108b07"
      },
      "outputs": [],
      "source": [
        "def FedAvg(model_state_dicts):\n",
        "    '''\n",
        "        Calculates and generates the FedAvg of the state_dict of a list of models. Returns the FedAvg state_dict.\n",
        "    '''\n",
        "    # Sum up tensors from all states\n",
        "    state_dict_sum = {} # Stores the sum of state parameters\n",
        "    for state_dict in model_state_dicts:\n",
        "        for key, params in state_dict.items():\n",
        "            if key in state_dict_sum:\n",
        "                state_dict_sum[key] += params.detach().clone()\n",
        "            else:\n",
        "                state_dict_sum[key] = params.detach().clone()\n",
        "\n",
        "    # Get Federated Average of clients' parameters\n",
        "    state_dict_avg = {}\n",
        "    for key in state_dict_sum:\n",
        "        state_dict_avg[key] = state_dict_sum[key] / len(model_state_dicts)\n",
        "\n",
        "    return state_dict_avg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_FedAvg(model_state_dicts, sv):\n",
        "    '''\n",
        "        Calculates and generates the FedAvg of the state_dict of a list of models. Returns the FedAvg state_dict.\n",
        "    '''\n",
        "    print(sv)\n",
        "    # Sum up tensors from all states\n",
        "    state_dict_sum = {} # Stores the sum of state parameters\n",
        "    for state_dict in model_state_dicts:\n",
        "        for key, params in state_dict.items():\n",
        "            if key in state_dict_sum:\n",
        "                state_dict_sum[key] += params.detach().clone()\n",
        "            else:\n",
        "                state_dict_sum[key] = params.detach().clone()\n",
        "\n",
        "    # Get Federated Average of clients' parameters\n",
        "    state_dict_avg = {}\n",
        "    for key in state_dict_sum:\n",
        "        state_dict_avg[key] = state_dict_sum[key] / len(model_state_dicts)\n",
        "\n",
        "    return state_dict_avg"
      ],
      "metadata": {
        "id": "jLMynfy1A0j0"
      },
      "id": "jLMynfy1A0j0",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "113063e1",
      "metadata": {
        "id": "113063e1"
      },
      "source": [
        "### FedAvg-Shapley server training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "2c0c1ba4",
      "metadata": {
        "id": "2c0c1ba4"
      },
      "outputs": [],
      "source": [
        "def evalFedAvgShapley(server, sv, round ,weighted_round = 9):\n",
        "    '''\n",
        "        >Evaluates and rewards clients based on marginal contributions in coalition permutations\n",
        "        >build server model by fedAvg\n",
        "    '''\n",
        "\n",
        "    # create server model\n",
        "    server_checkpoint = loadCheckpoint(server['filepath'])\n",
        "    server_model = FederatedModel().to(device)\n",
        "    server_model.load_state_dict(server_checkpoint['model_state_dict'])\n",
        "\n",
        "    # Evaluate server model\n",
        "    server_loss, server_acc, server_f1 = test(server['dataloader'], server_model, server['loss_func'])\n",
        "    print(f\"\\n>> Current Server Model Acc: {server_acc:>8f}, Loss: {server_loss:>8f}, F1: {server_f1:>8f}\\n\")\n",
        "\n",
        "    # Load client model state_dicts (simulating server sideloading client model parameters)\n",
        "    client_filepaths = glob.glob(f\"{server['client_filepath']}/client*.pt\")\n",
        "\n",
        "    client_checkpoints = {}\n",
        "    for client_filepath in client_filepaths:\n",
        "        client_checkpoint = loadCheckpoint(client_filepath)\n",
        "        client_checkpoints[client_checkpoint['name']] = client_checkpoint\n",
        "    client_names = [client_id for client_id in client_checkpoints]\n",
        "\n",
        "    max_length = len(client_names)\n",
        "    # We generate non-null powerset of selected clients\n",
        "    coalitions = list([frozenset(subset) for subset in powerset(client_names)])\n",
        "\n",
        "    # We generate order permutations of selected clients\n",
        "    orders = list(permutations(client_names))\n",
        "\n",
        "    #get your last coalition - new fedavg\n",
        "    if round == weighted_round :\n",
        "        all_model_state_dicts = [client_checkpoints[client_id]['model_state_dict'] for client_id in client_names]\n",
        "        fed_model_state_dict = custom_FedAvg(all_model_state_dicts, sv)\n",
        "        saveCheckpoint(\n",
        "            \"weighted_server\",\n",
        "            fed_model_state_dict,\n",
        "            server['optimizer'],\n",
        "            server['filepath'],\n",
        "        )\n",
        "    # We calculate the contributions of each coalition\n",
        "    print('FedAvg Coalition Evaluations:')\n",
        "\n",
        "    best_loss, best_acc, best_f1, best_utility = server_loss, server_acc, server_f1, 0.0\n",
        "    utilities = {}\n",
        "\n",
        "    fed_model = FederatedModel().to(device)\n",
        "\n",
        "    for coalition in coalitions:\n",
        "        coalition_names = [client_id for client_id in coalition]\n",
        "\n",
        "        # Get Federated Average of clients' parameters\n",
        "        model_state_dicts = [client_checkpoints[client_id]['model_state_dict'] for client_id in coalition_names]\n",
        "        fed_model_state_dict = FedAvg(model_state_dicts)\n",
        "\n",
        "        # Instantiate server model using FedAvg\n",
        "        fed_model.load_state_dict(fed_model_state_dict)\n",
        "\n",
        "        fed_model.eval()\n",
        "        # Evaluate FedAvg server model\n",
        "        eval_loss, eval_acc, eval_f1 = test(server['dataloader'], fed_model, FederatedLossFunc())\n",
        "\n",
        "        print(f\">> {'-'.join(coalition_names)} Acc: {eval_acc:>8f}, Loss: {eval_loss:>8f}, F1: {eval_f1:>8f}\")\n",
        "        utility_sum = 0\n",
        "        utilities[coalition] = {\n",
        "            'acc': eval_acc,\n",
        "        }\n",
        "\n",
        "        if len(coalition)  == max_length:\n",
        "            saveCheckpoint(\n",
        "                server['name'],\n",
        "                fed_model_state_dict,\n",
        "                server['optimizer'],\n",
        "                server['filepath'],\n",
        "            )\n",
        "\n",
        "    # print(\"this is your utility:\", utilities)\n",
        "    contributions = {}\n",
        "    for order in orders:\n",
        "        index = 1\n",
        "        prev_suborder = []\n",
        "\n",
        "        # Calculate contribution of each client in this order\n",
        "        for client_id in order:\n",
        "            cur_suborder = order[:index] # eg. ['A'] -> ['A','B'] -> ['A','B','C']\n",
        "            # If index > 1, we deduct this suborder's utility from prev suborder (eg. u(AB) - u(A) = c(B))\n",
        "            if index > 1:\n",
        "                cur_utilities = utilities[frozenset(cur_suborder)]\n",
        "                prev_utilities = utilities[frozenset(prev_suborder)]\n",
        "\n",
        "                ans = {}\n",
        "                for utility_metric in cur_utilities:\n",
        "                    ans[utility_metric] = cur_utilities[utility_metric] - prev_utilities[utility_metric]\n",
        "\n",
        "            # If index == 1, this is a single element's contribution (eg. u(A) = c(A))\n",
        "            else:\n",
        "                ans = utilities[frozenset([client_id])]\n",
        "                # {'acc': 0.1028}\n",
        "\n",
        "            # Add value to client's list of contributions\n",
        "            if not client_id in contributions:\n",
        "                    contributions[client_id] = {}\n",
        "\n",
        "            for utility_metric in ans:\n",
        "                if utility_metric in contributions[client_id]:\n",
        "                    contributions[client_id][utility_metric] += [ans[utility_metric]]\n",
        "                else:\n",
        "                    contributions[client_id][utility_metric] = [ans[utility_metric]]\n",
        "\n",
        "            index += 1\n",
        "            prev_suborder += [client_id]\n",
        "\n",
        "    # We calculate the Shapley Value of each client by averaging the sum of their contributions\n",
        "    print(f'\\nClient Shapley Values:')\n",
        "    for client_id in contributions:\n",
        "        txt = f'>> {client_id}:'\n",
        "        for metric in contributions[client_id]:\n",
        "            metric_values = contributions[client_id][metric]\n",
        "            contributions[client_id][metric] = sum(metric_values) / len(metric_values)\n",
        "            txt += f' {metric}: {contributions[client_id][metric]:>8f},'\n",
        "        print(txt)\n",
        "\n",
        "    # Output statistics\n",
        "    return  {name:vals['acc'] for name, vals in contributions.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "00b8af9c",
      "metadata": {
        "id": "00b8af9c"
      },
      "outputs": [],
      "source": [
        "def trainFedAvgShapleyModel(rounds=5, shapley_filter=True, coalition_limit=0):\n",
        "    '''\n",
        "        Train a model using FedAvg using Shapley Value\n",
        "    '''\n",
        "\n",
        "    loss, acc, f1, eval_time, best_coalitions, sv = [], [], [], [], [], []\n",
        "    for r in range(1, rounds+1):\n",
        "        print(f'\\n=======================\\n\\tROUND {r}\\n=======================')\n",
        "        clients_loss, clients_acc, clients_f1 = trainClients(clients, server)\n",
        "        clients_sv = evalFedAvgShapley(server, sv, round =r,weighted_round = 9)\n",
        "        sv += [clients_sv]# Shapley Values of every client\n",
        "\n",
        "    # Output statistics\n",
        "    return aggListOfDicts(loss), aggListOfDicts(acc), aggListOfDicts(f1), aggListOfDicts(sv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a FedAvg-Shapley model"
      ],
      "metadata": {
        "id": "4CZcmrogvLUG"
      },
      "id": "4CZcmrogvLUG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initalize server and clients\n",
        "server = initServer(model_path,'ShapleyValue',test_dataloader)\n",
        "clients = initClients(NUM_NORMAL_CLIENTS,NUM_FREERIDER_CLIENTS,NUM_ADVERSARIAL_CLIENTS,server,train_dataloaders)\n",
        "\n",
        "# Train and evaluate\n",
        "sv_loss, sv_acc, sv_f1, sv  = trainFedAvgShapleyModel(COMM_ROUNDS, shapley_filter=SHAPLEY_FILTER, coalition_limit=COALITION_LIMIT)"
      ],
      "metadata": {
        "id": "SwzYu7AIHNQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fa9f03-fe7f-4ca7-d712-b3bd78431f38"
      },
      "id": "SwzYu7AIHNQ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing server model...\n",
            "MediumMLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    lr: 0.1\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "\n",
            "\"server\" model saved as \"./models/ShapleyValue/server/server_model.pt\".\n",
            "\n",
            "Initializing clients...\n",
            "Client Name / Behaviour: [('client_0', 'NORMAL'), ('client_1', 'NORMAL'), ('client_2', 'NORMAL'), ('client_3', 'NORMAL'), ('client_4', 'ADVERSARIAL')] \n",
            "\n",
            "\n",
            "=======================\n",
            "\tROUND 1\n",
            "=======================\n",
            "Training client_0 over 10 epochs...\n",
            "client_0 (NORMAL) Test Acc: 0.100800, Loss: 2.290046, F1: 0.100376\n",
            "Training client_1 over 10 epochs...\n",
            "client_1 (NORMAL) Test Acc: 0.185500, Loss: 2.325365, F1: 0.185522\n",
            "Training client_2 over 10 epochs...\n",
            "client_2 (NORMAL) Test Acc: 0.098800, Loss: 2.299753, F1: 0.099090\n",
            "Training client_3 over 10 epochs...\n",
            "client_3 (NORMAL) Test Acc: 0.102800, Loss: 2.304755, F1: 0.102354\n",
            "client_4 (ADVERSARIAL) Test Acc: 0.123500, Loss: 2.302358, F1: 0.123517\n",
            "\n",
            ">> Current Server Model Acc: 0.080000, Loss: 2.301962, F1: 0.079806\n",
            "\n",
            "FedAvg Coalition Evaluations:\n",
            ">> client_0 Acc: 0.100800, Loss: 2.290046, F1: 0.100376\n",
            ">> client_4 Acc: 0.123500, Loss: 2.302358, F1: 0.123517\n",
            ">> client_3 Acc: 0.102800, Loss: 2.304755, F1: 0.102354\n",
            ">> client_2 Acc: 0.098800, Loss: 2.299753, F1: 0.099090\n",
            ">> client_1 Acc: 0.185500, Loss: 2.325365, F1: 0.185522\n",
            ">> client_4-client_0 Acc: 0.097400, Loss: 2.301719, F1: 0.097013\n",
            ">> client_3-client_0 Acc: 0.217400, Loss: 2.265017, F1: 0.217069\n",
            ">> client_2-client_0 Acc: 0.220000, Loss: 2.281350, F1: 0.219640\n",
            ">> client_1-client_0 Acc: 0.253900, Loss: 2.262383, F1: 0.253857\n",
            ">> client_4-client_3 Acc: 0.102800, Loss: 2.303746, F1: 0.102354\n",
            ">> client_2-client_4 Acc: 0.098200, Loss: 2.303025, F1: 0.098497\n",
            ">> client_4-client_1 Acc: 0.095800, Loss: 2.305959, F1: 0.096123\n",
            ">> client_2-client_3 Acc: 0.168600, Loss: 2.267958, F1: 0.168117\n",
            ">> client_1-client_3 Acc: 0.168500, Loss: 2.287388, F1: 0.168018\n",
            ">> client_2-client_1 Acc: 0.232800, Loss: 2.258763, F1: 0.233683\n",
            ">> client_4-client_3-client_0 Acc: 0.208200, Loss: 2.294462, F1: 0.207971\n",
            ">> client_2-client_4-client_0 Acc: 0.104800, Loss: 2.297734, F1: 0.104331\n",
            ">> client_4-client_1-client_0 Acc: 0.271600, Loss: 2.295120, F1: 0.272053\n",
            ">> client_2-client_3-client_0 Acc: 0.289300, Loss: 2.263847, F1: 0.288172\n",
            ">> client_1-client_3-client_0 Acc: 0.222200, Loss: 2.261007, F1: 0.221816\n",
            ">> client_2-client_1-client_0 Acc: 0.146400, Loss: 2.258724, F1: 0.146855\n",
            ">> client_2-client_4-client_3 Acc: 0.103500, Loss: 2.295323, F1: 0.103738\n",
            ">> client_4-client_1-client_3 Acc: 0.263300, Loss: 2.299761, F1: 0.262460\n",
            ">> client_2-client_4-client_1 Acc: 0.140400, Loss: 2.294685, F1: 0.141614\n",
            ">> client_2-client_1-client_3 Acc: 0.248300, Loss: 2.259520, F1: 0.247627\n",
            ">> client_2-client_4-client_3-client_0 Acc: 0.285800, Loss: 2.289134, F1: 0.285403\n",
            ">> client_4-client_1-client_3-client_0 Acc: 0.198700, Loss: 2.288935, F1: 0.197884\n",
            ">> client_2-client_4-client_1-client_0 Acc: 0.247600, Loss: 2.288296, F1: 0.248319\n",
            ">> client_2-client_1-client_3-client_0 Acc: 0.459900, Loss: 2.256198, F1: 0.460344\n",
            ">> client_2-client_4-client_1-client_3 Acc: 0.273300, Loss: 2.288621, F1: 0.273042\n",
            ">> client_0-client_1-client_2-client_4-client_3 Acc: 0.324100, Loss: 2.282719, F1: 0.324664\n",
            "\n",
            "Client Shapley Values:\n",
            ">> client_0: acc: 0.078577,\n",
            ">> client_4: acc: -0.007832,\n",
            ">> client_3: acc: 0.082243,\n",
            ">> client_2: acc: 0.073485,\n",
            ">> client_1: acc: 0.097627,\n",
            "\n",
            "=======================\n",
            "\tROUND 2\n",
            "=======================\n",
            "Training client_0 over 10 epochs...\n",
            "client_0 (NORMAL) Test Acc: 0.169100, Loss: 2.262165, F1: 0.169304\n",
            "Training client_1 over 10 epochs...\n",
            "client_1 (NORMAL) Test Acc: 0.175200, Loss: 2.345016, F1: 0.174644\n",
            "Training client_2 over 10 epochs...\n",
            "client_2 (NORMAL) Test Acc: 0.118700, Loss: 2.271415, F1: 0.118770\n",
            "Training client_3 over 10 epochs...\n",
            "client_3 (NORMAL) Test Acc: 0.159300, Loss: 2.301573, F1: 0.158920\n",
            "client_4 (ADVERSARIAL) Test Acc: 0.098100, Loss: 2.304394, F1: 0.098398\n",
            "\n",
            ">> Current Server Model Acc: 0.324100, Loss: 2.282719, F1: 0.324664\n",
            "\n",
            "FedAvg Coalition Evaluations:\n",
            ">> client_0 Acc: 0.169100, Loss: 2.262165, F1: 0.169304\n",
            ">> client_4 Acc: 0.098100, Loss: 2.304394, F1: 0.098398\n",
            ">> client_3 Acc: 0.159300, Loss: 2.301573, F1: 0.158920\n",
            ">> client_2 Acc: 0.118700, Loss: 2.271415, F1: 0.118770\n",
            ">> client_1 Acc: 0.175200, Loss: 2.345016, F1: 0.174644\n",
            ">> client_4-client_0 Acc: 0.097400, Loss: 2.300847, F1: 0.097013\n",
            ">> client_3-client_0 Acc: 0.303100, Loss: 2.226667, F1: 0.302512\n",
            ">> client_2-client_0 Acc: 0.278800, Loss: 2.250763, F1: 0.279173\n",
            ">> client_1-client_0 Acc: 0.302000, Loss: 2.218191, F1: 0.301424\n",
            ">> client_4-client_3 Acc: 0.102800, Loss: 2.301483, F1: 0.102354\n",
            ">> client_2-client_4 Acc: 0.098200, Loss: 2.302609, F1: 0.098497\n",
            ">> client_4-client_1 Acc: 0.095800, Loss: 2.301330, F1: 0.096123\n",
            ">> client_2-client_3 Acc: 0.210100, Loss: 2.231445, F1: 0.209157\n",
            ">> client_1-client_3 Acc: 0.149700, Loss: 2.270217, F1: 0.148734\n",
            ">> client_2-client_1 Acc: 0.216600, Loss: 2.213466, F1: 0.217662\n",
            ">> client_4-client_3-client_0 Acc: 0.210500, Loss: 2.287126, F1: 0.210245\n",
            ">> client_2-client_4-client_0 Acc: 0.254100, Loss: 2.292856, F1: 0.254055\n",
            ">> client_4-client_1-client_0 Acc: 0.355400, Loss: 2.285739, F1: 0.356309\n",
            ">> client_2-client_3-client_0 Acc: 0.319700, Loss: 2.226220, F1: 0.319620\n",
            ">> client_1-client_3-client_0 Acc: 0.314500, Loss: 2.217171, F1: 0.314478\n",
            ">> client_2-client_1-client_0 Acc: 0.320200, Loss: 2.216370, F1: 0.321499\n",
            ">> client_2-client_4-client_3 Acc: 0.116400, Loss: 2.288073, F1: 0.116495\n",
            ">> client_4-client_1-client_3 Acc: 0.240500, Loss: 2.287855, F1: 0.239913\n",
            ">> client_2-client_4-client_1 Acc: 0.155600, Loss: 2.285107, F1: 0.156646\n",
            ">> client_2-client_1-client_3 Acc: 0.284300, Loss: 2.215652, F1: 0.283920\n",
            ">> client_2-client_4-client_3-client_0 Acc: 0.283100, Loss: 2.277529, F1: 0.283426\n",
            ">> client_4-client_1-client_3-client_0 Acc: 0.340600, Loss: 2.272778, F1: 0.340289\n",
            ">> client_2-client_4-client_1-client_0 Acc: 0.216900, Loss: 2.275049, F1: 0.217267\n",
            ">> client_2-client_1-client_3-client_0 Acc: 0.445600, Loss: 2.211794, F1: 0.445510\n",
            ">> client_2-client_4-client_1-client_3 Acc: 0.297700, Loss: 2.272309, F1: 0.297172\n",
            ">> client_0-client_1-client_2-client_4-client_3 Acc: 0.420900, Loss: 2.263701, F1: 0.421084\n",
            "\n",
            "Client Shapley Values:\n",
            ">> client_0: acc: 0.134470,\n",
            ">> client_4: acc: -0.006005,\n",
            ">> client_3: acc: 0.110212,\n",
            ">> client_2: acc: 0.069337,\n",
            ">> client_1: acc: 0.112887,\n",
            "\n",
            "=======================\n",
            "\tROUND 3\n",
            "=======================\n",
            "Training client_0 over 10 epochs...\n",
            "client_0 (NORMAL) Test Acc: 0.188700, Loss: 2.213953, F1: 0.187994\n",
            "Training client_1 over 10 epochs...\n",
            "client_1 (NORMAL) Test Acc: 0.187200, Loss: 2.242396, F1: 0.187203\n",
            "Training client_2 over 10 epochs...\n",
            "client_2 (NORMAL) Test Acc: 0.213300, Loss: 2.226768, F1: 0.213706\n",
            "Training client_3 over 10 epochs...\n",
            "client_3 (NORMAL) Test Acc: 0.208100, Loss: 2.270179, F1: 0.207180\n",
            "client_4 (ADVERSARIAL) Test Acc: 0.105800, Loss: 2.303737, F1: 0.106013\n",
            "\n",
            ">> Current Server Model Acc: 0.420900, Loss: 2.263701, F1: 0.421084\n",
            "\n",
            "FedAvg Coalition Evaluations:\n",
            ">> client_0 Acc: 0.188700, Loss: 2.213953, F1: 0.187994\n",
            ">> client_4 Acc: 0.105800, Loss: 2.303737, F1: 0.106013\n",
            ">> client_3 Acc: 0.208100, Loss: 2.270179, F1: 0.207180\n",
            ">> client_2 Acc: 0.213300, Loss: 2.226768, F1: 0.213706\n",
            ">> client_1 Acc: 0.187200, Loss: 2.242396, F1: 0.187203\n",
            ">> client_4-client_0 Acc: 0.187200, Loss: 2.298340, F1: 0.187203\n",
            ">> client_3-client_0 Acc: 0.390800, Loss: 2.138495, F1: 0.389933\n",
            ">> client_2-client_0 Acc: 0.250300, Loss: 2.194895, F1: 0.250297\n",
            ">> client_1-client_0 Acc: 0.391500, Loss: 2.127540, F1: 0.391317\n",
            ">> client_4-client_3 Acc: 0.102800, Loss: 2.294332, F1: 0.102354\n",
            ">> client_2-client_4 Acc: 0.098200, Loss: 2.299025, F1: 0.098497\n",
            ">> client_4-client_1 Acc: 0.097800, Loss: 2.291355, F1: 0.098101\n",
            ">> client_2-client_3 Acc: 0.307600, Loss: 2.144662, F1: 0.306270\n",
            ">> client_1-client_3 Acc: 0.259700, Loss: 2.195679, F1: 0.259593\n",
            ">> client_2-client_1 Acc: 0.355400, Loss: 2.117638, F1: 0.357002\n",
            ">> client_4-client_3-client_0 Acc: 0.248200, Loss: 2.269553, F1: 0.248220\n",
            ">> client_2-client_4-client_0 Acc: 0.297000, Loss: 2.281472, F1: 0.297172\n",
            ">> client_4-client_1-client_0 Acc: 0.368400, Loss: 2.267599, F1: 0.369165\n",
            ">> client_2-client_3-client_0 Acc: 0.346700, Loss: 2.143279, F1: 0.346321\n",
            ">> client_1-client_3-client_0 Acc: 0.345800, Loss: 2.120374, F1: 0.345431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_round_sv = {key:torch.tensor(sv[str(key)][-1]) for key in sv }"
      ],
      "metadata": {
        "id": "wLfOi7DNUhdj"
      },
      "id": "wLfOi7DNUhdj",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_round_sv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tFZR8LUUhxi",
        "outputId": "ff5add6a-ffe3-4f36-8908-f7a834b972c0"
      },
      "id": "9tFZR8LUUhxi",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_0': tensor(0.1489),\n",
              " 'client_4': tensor(-0.0237),\n",
              " 'client_3': tensor(0.1309),\n",
              " 'client_2': tensor(0.1610),\n",
              " 'client_1': tensor(0.1923)}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write the weighted federated learning"
      ],
      "metadata": {
        "id": "c8s5t-X9V3b6"
      },
      "id": "c8s5t-X9V3b6",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_last_round_sv = {}\n"
      ],
      "metadata": {
        "id": "4lfjjfjCV_FX"
      },
      "id": "4lfjjfjCV_FX",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in last_round_sv:\n",
        "    softmax_last_round_sv[key] = torch.exp(last_round_sv[key])/sum([torch.exp(v) for _,v in last_round_sv.items() ])"
      ],
      "metadata": {
        "id": "rEuVDYkmYG9b"
      },
      "id": "rEuVDYkmYG9b",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_last_round_sv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzltEvGtZzxb",
        "outputId": "00652dca-b158-4c2f-d875-1c7df3525767"
      },
      "id": "UzltEvGtZzxb",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_0': tensor(0.2049),\n",
              " 'client_4': tensor(0.1724),\n",
              " 'client_3': tensor(0.2013),\n",
              " 'client_2': tensor(0.2074),\n",
              " 'client_1': tensor(0.2140)}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sv\n",
        "client weights\n",
        "weighted fedAvg\n",
        "\n",
        "=> customized fedavg-->server modetl\n",
        "=> acc"
      ],
      "metadata": {
        "id": "fYTP3uFmaoSd"
      },
      "id": "fYTP3uFmaoSd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LhOjwFjgtIJF",
        "EMhYlYkZtMHc",
        "elz2GPwms4wW",
        "9e1d7f0e",
        "83c3c954",
        "WQnmC_Lvtngj",
        "d0a0ce58",
        "a03c568b",
        "83d386ef"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}